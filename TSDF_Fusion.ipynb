{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tsdf fusion",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMaJM/Z51nQX1k79te7l+zM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giogia/Scene-Reconstruction/blob/master/tsdf_fusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUUKNMdzOsnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxI64HVUOU-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from numba import njit, prange\n",
        "from skimage import measure\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "\n",
        "%matplotlib inline \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "try:\n",
        "    import pycuda.driver as cuda\n",
        "    import pycuda.autoinit\n",
        "    from pycuda.compiler import SourceModule\n",
        "    FUSION_GPU_MODE = 1\n",
        "\n",
        "except Exception as err:\n",
        "    print('Warning: {}'.format(err))\n",
        "    print('Failed to import PyCUDA. Running fusion in CPU mode.')\n",
        "    FUSION_GPU_MODE = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sipj4ElSQfmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def read_csv(file, field, row_number=0):\n",
        "    reader = csv.DictReader(open(file))\n",
        "    row = list(reader)[row_number]\n",
        "\n",
        "    return literal_eval(row[field])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70kXMhVZTTGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from OpenEXR import InputFile\n",
        "from Imath import PixelType\n",
        "\n",
        "def exr_to_color(path):\n",
        "    file = InputFile(path)\n",
        "    window = file.header()['dataWindow']\n",
        "    channels = ('R', 'G', 'B')\n",
        "\n",
        "    size = (window.max.y - window.min.y + 1, window.max.x - window.min.x + 1)\n",
        "\n",
        "    channels_tuple = [np.frombuffer(channel, dtype=np.float32)\n",
        "                      for channel in file.channels(channels, PixelType(PixelType.FLOAT))]\n",
        "    exr_array = np.dstack(channels_tuple)\n",
        "\n",
        "    return exr_array.reshape(size + (len(channels_tuple),))\n",
        "\n",
        "\n",
        "def exr_to_depth(path, background=True):\n",
        "    file = InputFile(path)\n",
        "    window = file.header()['dataWindow']\n",
        "    size = (window.max.y - window.min.y + 1, window.max.x - window.min.x + 1)\n",
        "\n",
        "    exr_depth = file.channel('Z', PixelType(PixelType.FLOAT))\n",
        "    exr_depth = np.fromstring(exr_depth, dtype=np.float32)\n",
        "\n",
        "    # filter out background\n",
        "    threshold = np.unique(exr_depth)[-2]\n",
        "    exr_depth[exr_depth > threshold] = threshold if background else 0\n",
        "\n",
        "    return np.reshape(exr_depth, size)\n",
        "\n",
        "def show_array(data):\n",
        "\n",
        "    data /= np.max(data)\n",
        "    plt.imshow(data, interpolation='bicubic')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyxFVa0XNvND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TSDFVolume:\n",
        "    \"\"\"Volumetric TSDF Fusion of RGB-D Images.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, vol_bnds, voxel_size, use_gpu=True):\n",
        "        \"\"\"Constructor.\n",
        "\n",
        "    Args:\n",
        "      vol_bnds (ndarray): An ndarray of shape (3, 2). Specifies the\n",
        "        xyz bounds (min/max) in meters.\n",
        "      voxel_size (float): The volume discretization in meters.\n",
        "    \"\"\"\n",
        "        vol_bnds = np.asarray(vol_bnds)\n",
        "        assert vol_bnds.shape == (3, 2), \"[!] `vol_bnds` should be of shape (3, 2).\"\n",
        "\n",
        "        # Define voxel volume parameters\n",
        "        self._vol_bnds = vol_bnds\n",
        "        self._voxel_size = float(voxel_size)\n",
        "        self._trunc_margin = 5 * self._voxel_size  # truncation on SDF\n",
        "        self._color_const = 256 * 256\n",
        "\n",
        "        # Adjust volume bounds and ensure C-order contiguous\n",
        "        self._vol_dim = np.ceil((self._vol_bnds[:, 1] - self._vol_bnds[:, 0]) / self._voxel_size).copy(\n",
        "            order='C').astype(int)\n",
        "        self._vol_bnds[:, 1] = self._vol_bnds[:, 0] + self._vol_dim * self._voxel_size\n",
        "        self._vol_origin = self._vol_bnds[:, 0].copy(order='C').astype(np.float32)\n",
        "\n",
        "        print(\"Voxel volume size: {} x {} x {} - # points: {:,}\".format(\n",
        "            self._vol_dim[0], self._vol_dim[1], self._vol_dim[2],\n",
        "            self._vol_dim[0] * self._vol_dim[1] * self._vol_dim[2])\n",
        "        )\n",
        "\n",
        "        # Initialize pointers to voxel volume in CPU memory\n",
        "        self._tsdf_vol_cpu = np.ones(self._vol_dim).astype(np.float32)\n",
        "        # for computing the cumulative moving average of observations per voxel\n",
        "        self._weight_vol_cpu = np.zeros(self._vol_dim).astype(np.float32)\n",
        "        self._color_vol_cpu = np.zeros(self._vol_dim).astype(np.float32)\n",
        "\n",
        "        self.gpu_mode = use_gpu and FUSION_GPU_MODE\n",
        "\n",
        "        # Copy voxel volumes to GPU\n",
        "        if self.gpu_mode:\n",
        "            self._tsdf_vol_gpu = cuda.mem_alloc(self._tsdf_vol_cpu.nbytes)\n",
        "            cuda.memcpy_htod(self._tsdf_vol_gpu, self._tsdf_vol_cpu)\n",
        "            self._weight_vol_gpu = cuda.mem_alloc(self._weight_vol_cpu.nbytes)\n",
        "            cuda.memcpy_htod(self._weight_vol_gpu, self._weight_vol_cpu)\n",
        "            self._color_vol_gpu = cuda.mem_alloc(self._color_vol_cpu.nbytes)\n",
        "            cuda.memcpy_htod(self._color_vol_gpu, self._color_vol_cpu)\n",
        "\n",
        "            # Cuda kernel function (C++)\n",
        "            self._cuda_src_mod = SourceModule(\"\"\"\n",
        "        __global__ void integrate(float * tsdf_vol,\n",
        "                                  float * weight_vol,\n",
        "                                  float * color_vol,\n",
        "                                  float * vol_dim,\n",
        "                                  float * vol_origin,\n",
        "                                  float * cam_intr,\n",
        "                                  float * cam_pose,\n",
        "                                  float * other_params,\n",
        "                                  float * color_im,\n",
        "                                  float * depth_im) {\n",
        "          // Get voxel index\n",
        "          int gpu_loop_idx = (int) other_params[0];\n",
        "          int max_threads_per_block = blockDim.x;\n",
        "          int block_idx = blockIdx.z*gridDim.y*gridDim.x+blockIdx.y*gridDim.x+blockIdx.x;\n",
        "          int voxel_idx = gpu_loop_idx*gridDim.x*gridDim.y*gridDim.z*max_threads_per_block+block_idx*max_threads_per_block+threadIdx.x;\n",
        "          int vol_dim_x = (int) vol_dim[0];\n",
        "          int vol_dim_y = (int) vol_dim[1];\n",
        "          int vol_dim_z = (int) vol_dim[2];\n",
        "          if (voxel_idx > vol_dim_x*vol_dim_y*vol_dim_z)\n",
        "              return;\n",
        "          // Get voxel grid coordinates (note: be careful when casting)\n",
        "          float voxel_x = floorf(((float)voxel_idx)/((float)(vol_dim_y*vol_dim_z)));\n",
        "          float voxel_y = floorf(((float)(voxel_idx-((int)voxel_x)*vol_dim_y*vol_dim_z))/((float)vol_dim_z));\n",
        "          float voxel_z = (float)(voxel_idx-((int)voxel_x)*vol_dim_y*vol_dim_z-((int)voxel_y)*vol_dim_z);\n",
        "          // Voxel grid coordinates to world coordinates\n",
        "          float voxel_size = other_params[1];\n",
        "          float pt_x = vol_origin[0]+voxel_x*voxel_size;\n",
        "          float pt_y = vol_origin[1]+voxel_y*voxel_size;\n",
        "          float pt_z = vol_origin[2]+voxel_z*voxel_size;\n",
        "          // World coordinates to camera coordinates\n",
        "          float tmp_pt_x = pt_x-cam_pose[0*4+3];\n",
        "          float tmp_pt_y = pt_y-cam_pose[1*4+3];\n",
        "          float tmp_pt_z = pt_z-cam_pose[2*4+3];\n",
        "          float cam_pt_x = cam_pose[0*4+0]*tmp_pt_x+cam_pose[1*4+0]*tmp_pt_y+cam_pose[2*4+0]*tmp_pt_z;\n",
        "          float cam_pt_y = cam_pose[0*4+1]*tmp_pt_x+cam_pose[1*4+1]*tmp_pt_y+cam_pose[2*4+1]*tmp_pt_z;\n",
        "          float cam_pt_z = cam_pose[0*4+2]*tmp_pt_x+cam_pose[1*4+2]*tmp_pt_y+cam_pose[2*4+2]*tmp_pt_z;\n",
        "          // Camera coordinates to image pixels\n",
        "          int pixel_x = (int) roundf(cam_intr[0*3+0]*(cam_pt_x/cam_pt_z)+cam_intr[0*3+2]);\n",
        "          int pixel_y = (int) roundf(cam_intr[1*3+1]*(cam_pt_y/cam_pt_z)+cam_intr[1*3+2]);\n",
        "          // Skip if outside view frustum\n",
        "          int im_h = (int) other_params[2];\n",
        "          int im_w = (int) other_params[3];\n",
        "          if (pixel_x < 0 || pixel_x >= im_w || pixel_y < 0 || pixel_y >= im_h || cam_pt_z<0)\n",
        "              return;\n",
        "          // Skip invalid depth\n",
        "          float depth_value = depth_im[pixel_y*im_w+pixel_x];\n",
        "          if (depth_value == 0)\n",
        "              return;\n",
        "          // Integrate TSDF\n",
        "          float trunc_margin = other_params[4];\n",
        "          float depth_diff = depth_value-cam_pt_z;\n",
        "          if (depth_diff < -trunc_margin)\n",
        "              return;\n",
        "          float dist = fmin(1.0f,depth_diff/trunc_margin);\n",
        "          float w_old = weight_vol[voxel_idx];\n",
        "          float obs_weight = other_params[5];\n",
        "          float w_new = w_old + obs_weight;\n",
        "          weight_vol[voxel_idx] = w_new;\n",
        "          tsdf_vol[voxel_idx] = (tsdf_vol[voxel_idx]*w_old+obs_weight*dist)/w_new;\n",
        "          // Integrate color\n",
        "          float old_color = color_vol[voxel_idx];\n",
        "          float old_b = floorf(old_color/(256*256));\n",
        "          float old_g = floorf((old_color-old_b*256*256)/256);\n",
        "          float old_r = old_color-old_b*256*256-old_g*256;\n",
        "          float new_color = color_im[pixel_y*im_w+pixel_x];\n",
        "          float new_b = floorf(new_color/(256*256));\n",
        "          float new_g = floorf((new_color-new_b*256*256)/256);\n",
        "          float new_r = new_color-new_b*256*256-new_g*256;\n",
        "          new_b = fmin(roundf((old_b*w_old+obs_weight*new_b)/w_new),255.0f);\n",
        "          new_g = fmin(roundf((old_g*w_old+obs_weight*new_g)/w_new),255.0f);\n",
        "          new_r = fmin(roundf((old_r*w_old+obs_weight*new_r)/w_new),255.0f);\n",
        "          color_vol[voxel_idx] = new_b*256*256+new_g*256+new_r;\n",
        "        }\"\"\")\n",
        "\n",
        "            self._cuda_integrate = self._cuda_src_mod.get_function(\"integrate\")\n",
        "\n",
        "            # Determine block/grid size on GPU\n",
        "            gpu_dev = cuda.Device(0)\n",
        "            self._max_gpu_threads_per_block = gpu_dev.MAX_THREADS_PER_BLOCK\n",
        "            n_blocks = int(np.ceil(float(np.prod(self._vol_dim)) / float(self._max_gpu_threads_per_block)))\n",
        "            grid_dim_x = min(gpu_dev.MAX_GRID_DIM_X, int(np.floor(np.cbrt(n_blocks))))\n",
        "            grid_dim_y = min(gpu_dev.MAX_GRID_DIM_Y, int(np.floor(np.sqrt(n_blocks / grid_dim_x))))\n",
        "            grid_dim_z = min(gpu_dev.MAX_GRID_DIM_Z, int(np.ceil(float(n_blocks) / float(grid_dim_x * grid_dim_y))))\n",
        "            self._max_gpu_grid_dim = np.array([grid_dim_x, grid_dim_y, grid_dim_z]).astype(int)\n",
        "            self._n_gpu_loops = int(np.ceil(float(np.prod(self._vol_dim)) / float(\n",
        "                np.prod(self._max_gpu_grid_dim) * self._max_gpu_threads_per_block)))\n",
        "\n",
        "        else:\n",
        "            # Get voxel grid coordinates\n",
        "            xv, yv, zv = np.meshgrid(\n",
        "                range(self._vol_dim[0]),\n",
        "                range(self._vol_dim[1]),\n",
        "                range(self._vol_dim[2]),\n",
        "                indexing='ij'\n",
        "            )\n",
        "            self.vox_coords = np.concatenate([\n",
        "                xv.reshape(1, -1),\n",
        "                yv.reshape(1, -1),\n",
        "                zv.reshape(1, -1)\n",
        "            ], axis=0).astype(int).T\n",
        "\n",
        "    @staticmethod\n",
        "    @njit(parallel=True)\n",
        "    def vox2world(vol_origin, vox_coords, vox_size):\n",
        "        \"\"\"Convert voxel grid coordinates to world coordinates.\n",
        "    \"\"\"\n",
        "        vol_origin = vol_origin.astype(np.float32)\n",
        "        vox_coords = vox_coords.astype(np.float32)\n",
        "        cam_pts = np.empty_like(vox_coords, dtype=np.float32)\n",
        "        for i in prange(vox_coords.shape[0]):\n",
        "            for j in range(3):\n",
        "                cam_pts[i, j] = vol_origin[j] + (vox_size * vox_coords[i, j])\n",
        "        return cam_pts\n",
        "\n",
        "    @staticmethod\n",
        "    @njit(parallel=True)\n",
        "    def cam2pix(cam_pts, intr):\n",
        "        \"\"\"Convert camera coordinates to pixel coordinates.\n",
        "    \"\"\"\n",
        "        intr = intr.astype(np.float32)\n",
        "        fx, fy = intr[0, 0], intr[1, 1]\n",
        "        cx, cy = intr[0, 2], intr[1, 2]\n",
        "        pix = np.empty((cam_pts.shape[0], 2), dtype=np.int64)\n",
        "        for i in prange(cam_pts.shape[0]):\n",
        "            pix[i, 0] = int(np.round((cam_pts[i, 0] * fx / cam_pts[i, 2]) + cx))\n",
        "            pix[i, 1] = int(np.round((cam_pts[i, 1] * fy / cam_pts[i, 2]) + cy))\n",
        "        return pix\n",
        "\n",
        "    @staticmethod\n",
        "    @njit(parallel=True)\n",
        "    def integrate_tsdf(tsdf_vol, dist, w_old, obs_weight):\n",
        "        \"\"\"Integrate the TSDF volume.\n",
        "    \"\"\"\n",
        "        tsdf_vol_int = np.empty_like(tsdf_vol, dtype=np.float32)\n",
        "        w_new = np.empty_like(w_old, dtype=np.float32)\n",
        "        for i in prange(len(tsdf_vol)):\n",
        "            w_new[i] = w_old[i] + obs_weight\n",
        "            tsdf_vol_int[i] = (w_old[i] * tsdf_vol[i] + obs_weight * dist[i]) / w_new[i]\n",
        "        return tsdf_vol_int, w_new\n",
        "\n",
        "    def integrate(self, color_im, depth_im, cam_intr, cam_pose, obs_weight=1.):\n",
        "        \"\"\"Integrate an RGB-D frame into the TSDF volume.\n",
        "\n",
        "    Args:\n",
        "      color_im (ndarray): An RGB image of shape (H, W, 3).\n",
        "      depth_im (ndarray): A depth image of shape (H, W).\n",
        "      cam_intr (ndarray): The camera intrinsics matrix of shape (3, 3).\n",
        "      cam_pose (ndarray): The camera pose (i.e. extrinsics) of shape (4, 4).\n",
        "      obs_weight (float): The weight to assign for the current observation. A higher\n",
        "        value\n",
        "    \"\"\"\n",
        "        im_h, im_w = depth_im.shape\n",
        "\n",
        "        # Fold RGB color image into a single channel image\n",
        "        color_im = color_im.astype(np.float32)\n",
        "        color_im = np.floor(color_im[..., 2] * self._color_const + color_im[..., 1] * 256 + color_im[..., 0])\n",
        "\n",
        "        if self.gpu_mode:  # GPU mode: integrate voxel volume (calls CUDA kernel)\n",
        "            for gpu_loop_idx in range(self._n_gpu_loops):\n",
        "                self._cuda_integrate(self._tsdf_vol_gpu,\n",
        "                                     self._weight_vol_gpu,\n",
        "                                     self._color_vol_gpu,\n",
        "                                     cuda.InOut(self._vol_dim.astype(np.float32)),\n",
        "                                     cuda.InOut(self._vol_origin.astype(np.float32)),\n",
        "                                     cuda.InOut(cam_intr.reshape(-1).astype(np.float32)),\n",
        "                                     cuda.InOut(cam_pose.reshape(-1).astype(np.float32)),\n",
        "                                     cuda.InOut(np.asarray([\n",
        "                                         gpu_loop_idx,\n",
        "                                         self._voxel_size,\n",
        "                                         im_h,\n",
        "                                         im_w,\n",
        "                                         self._trunc_margin,\n",
        "                                         obs_weight\n",
        "                                     ], np.float32)),\n",
        "                                     cuda.InOut(color_im.reshape(-1).astype(np.float32)),\n",
        "                                     cuda.InOut(depth_im.reshape(-1).astype(np.float32)),\n",
        "                                     block=(self._max_gpu_threads_per_block, 1, 1),\n",
        "                                     grid=(\n",
        "                                         int(self._max_gpu_grid_dim[0]),\n",
        "                                         int(self._max_gpu_grid_dim[1]),\n",
        "                                         int(self._max_gpu_grid_dim[2]),\n",
        "                                     )\n",
        "                                     )\n",
        "        else:  # CPU mode: integrate voxel volume (vectorized implementation)\n",
        "            # Convert voxel grid coordinates to pixel coordinates\n",
        "            cam_pts = self.vox2world(self._vol_origin, self.vox_coords, self._voxel_size)\n",
        "            cam_pts = rigid_transform(cam_pts, np.linalg.inv(cam_pose))\n",
        "            pix_z = cam_pts[:, 2]\n",
        "            pix = self.cam2pix(cam_pts, cam_intr)\n",
        "            pix_x, pix_y = pix[:, 0], pix[:, 1]\n",
        "\n",
        "            # Eliminate pixels outside view frustum\n",
        "            valid_pix = np.logical_and(pix_x >= 0,\n",
        "                                       np.logical_and(pix_x < im_w,\n",
        "                                                      np.logical_and(pix_y >= 0,\n",
        "                                                                     np.logical_and(pix_y < im_h,\n",
        "                                                                                    pix_z > 0))))\n",
        "            depth_val = np.zeros(pix_x.shape)\n",
        "            depth_val[valid_pix] = depth_im[pix_y[valid_pix], pix_x[valid_pix]]\n",
        "\n",
        "            # Integrate TSDF\n",
        "            depth_diff = depth_val - pix_z\n",
        "            valid_pts = np.logical_and(depth_val > 0, depth_diff >= -self._trunc_margin)\n",
        "            dist = np.minimum(1, depth_diff / self._trunc_margin)\n",
        "            valid_vox_x = self.vox_coords[valid_pts, 0]\n",
        "            valid_vox_y = self.vox_coords[valid_pts, 1]\n",
        "            valid_vox_z = self.vox_coords[valid_pts, 2]\n",
        "            w_old = self._weight_vol_cpu[valid_vox_x, valid_vox_y, valid_vox_z]\n",
        "            tsdf_vals = self._tsdf_vol_cpu[valid_vox_x, valid_vox_y, valid_vox_z]\n",
        "            valid_dist = dist[valid_pts]\n",
        "            tsdf_vol_new, w_new = self.integrate_tsdf(tsdf_vals, valid_dist, w_old, obs_weight)\n",
        "            self._weight_vol_cpu[valid_vox_x, valid_vox_y, valid_vox_z] = w_new\n",
        "            self._tsdf_vol_cpu[valid_vox_x, valid_vox_y, valid_vox_z] = tsdf_vol_new\n",
        "\n",
        "            # Integrate color\n",
        "            old_color = self._color_vol_cpu[valid_vox_x, valid_vox_y, valid_vox_z]\n",
        "            old_b = np.floor(old_color / self._color_const)\n",
        "            old_g = np.floor((old_color - old_b * self._color_const) / 256)\n",
        "            old_r = old_color - old_b * self._color_const - old_g * 256\n",
        "            new_color = color_im[pix_y[valid_pts], pix_x[valid_pts]]\n",
        "            new_b = np.floor(new_color / self._color_const)\n",
        "            new_g = np.floor((new_color - new_b * self._color_const) / 256)\n",
        "            new_r = new_color - new_b * self._color_const - new_g * 256\n",
        "            new_b = np.minimum(255., np.round((w_old * old_b + obs_weight * new_b) / w_new))\n",
        "            new_g = np.minimum(255., np.round((w_old * old_g + obs_weight * new_g) / w_new))\n",
        "            new_r = np.minimum(255., np.round((w_old * old_r + obs_weight * new_r) / w_new))\n",
        "            self._color_vol_cpu[valid_vox_x, valid_vox_y, valid_vox_z] = new_b * self._color_const + new_g * 256 + new_r\n",
        "\n",
        "    def get_volume(self):\n",
        "        if self.gpu_mode:\n",
        "            cuda.memcpy_dtoh(self._tsdf_vol_cpu, self._tsdf_vol_gpu)\n",
        "            cuda.memcpy_dtoh(self._color_vol_cpu, self._color_vol_gpu)\n",
        "        return self._tsdf_vol_cpu, self._color_vol_cpu\n",
        "\n",
        "    def get_point_cloud(self):\n",
        "        \"\"\"Extract a point cloud from the voxel volume.\n",
        "    \"\"\"\n",
        "        tsdf_vol, color_vol = self.get_volume()\n",
        "\n",
        "        # Marching cubes\n",
        "        verts = measure.marching_cubes_lewiner(tsdf_vol, level=0)[0]\n",
        "        verts_ind = np.round(verts).astype(int)\n",
        "        verts = verts * self._voxel_size + self._vol_origin\n",
        "\n",
        "        # Get vertex colors\n",
        "        rgb_vals = color_vol[verts_ind[:, 0], verts_ind[:, 1], verts_ind[:, 2]]\n",
        "        colors_b = np.floor(rgb_vals / self._color_const)\n",
        "        colors_g = np.floor((rgb_vals - colors_b * self._color_const) / 256)\n",
        "        colors_r = rgb_vals - colors_b * self._color_const - colors_g * 256\n",
        "        colors = np.floor(np.asarray([colors_r, colors_g, colors_b])).T\n",
        "        colors = colors.astype(np.uint8)\n",
        "\n",
        "        pc = np.hstack([verts, colors])\n",
        "        return pc\n",
        "\n",
        "    def get_mesh(self):\n",
        "        \"\"\"Compute a mesh from the voxel volume using marching cubes.\n",
        "    \"\"\"\n",
        "        tsdf_vol, color_vol = self.get_volume()\n",
        "\n",
        "        # Marching cubes\n",
        "        verts, faces, norms, vals = measure.marching_cubes_lewiner(tsdf_vol, level=0)\n",
        "        verts_ind = np.round(verts).astype(int)\n",
        "        verts = verts * self._voxel_size + self._vol_origin  # voxel grid coordinates to world coordinates\n",
        "\n",
        "        # Get vertex colors\n",
        "        rgb_vals = color_vol[verts_ind[:, 0], verts_ind[:, 1], verts_ind[:, 2]]\n",
        "        colors_b = np.floor(rgb_vals / self._color_const)\n",
        "        colors_g = np.floor((rgb_vals - colors_b * self._color_const) / 256)\n",
        "        colors_r = rgb_vals - colors_b * self._color_const - colors_g * 256\n",
        "        colors = np.floor(np.asarray([colors_r, colors_g, colors_b])).T\n",
        "        colors = colors.astype(np.uint8)\n",
        "        return verts, faces, norms, colors\n",
        "\n",
        "\n",
        "def rigid_transform(xyz, transform):\n",
        "    \"\"\"Applies a rigid transform to an (N, 3) pointcloud.\n",
        "  \"\"\"\n",
        "    xyz_h = np.hstack([xyz, np.ones((len(xyz), 1), dtype=np.float32)])\n",
        "    xyz_t_h = np.dot(transform, xyz_h.T).T\n",
        "    return xyz_t_h[:, :3]\n",
        "\n",
        "\n",
        "def get_view_frustum(depth_im, cam_intr, cam_pose):\n",
        "    \"\"\"Get corners of 3D camera view frustum of depth image\n",
        "  \"\"\"\n",
        "    im_h = depth_im.shape[0]\n",
        "    im_w = depth_im.shape[1]\n",
        "    max_depth = np.max(depth_im)\n",
        "    view_frust_pts = np.array([\n",
        "        (np.array([0, 0, 0, im_w, im_w]) - cam_intr[0, 2]) * np.array([0, max_depth, max_depth, max_depth, max_depth]) /\n",
        "        cam_intr[0, 0],\n",
        "        (np.array([0, 0, im_h, 0, im_h]) - cam_intr[1, 2]) * np.array([0, max_depth, max_depth, max_depth, max_depth]) /\n",
        "        cam_intr[1, 1],\n",
        "        np.array([0, max_depth, max_depth, max_depth, max_depth])\n",
        "    ])\n",
        "    view_frust_pts = rigid_transform(view_frust_pts.T, cam_pose).T\n",
        "    return view_frust_pts\n",
        "\n",
        "\n",
        "def meshwrite(filename, verts, faces, norms, colors):\n",
        "    \"\"\"Save a 3D mesh to a polygon .ply file.\n",
        "  \"\"\"\n",
        "    # Write header\n",
        "    ply_file = open(filename, 'w')\n",
        "    ply_file.write(\"ply\\n\")\n",
        "    ply_file.write(\"format ascii 1.0\\n\")\n",
        "    ply_file.write(\"element vertex %d\\n\" % (verts.shape[0]))\n",
        "    ply_file.write(\"property float x\\n\")\n",
        "    ply_file.write(\"property float y\\n\")\n",
        "    ply_file.write(\"property float z\\n\")\n",
        "    ply_file.write(\"property float nx\\n\")\n",
        "    ply_file.write(\"property float ny\\n\")\n",
        "    ply_file.write(\"property float nz\\n\")\n",
        "    ply_file.write(\"property uchar red\\n\")\n",
        "    ply_file.write(\"property uchar green\\n\")\n",
        "    ply_file.write(\"property uchar blue\\n\")\n",
        "    ply_file.write(\"element face %d\\n\" % (faces.shape[0]))\n",
        "    ply_file.write(\"property list uchar int vertex_index\\n\")\n",
        "    ply_file.write(\"end_header\\n\")\n",
        "\n",
        "    # Write vertex list\n",
        "    for i in range(verts.shape[0]):\n",
        "        ply_file.write(\"%f %f %f %f %f %f %d %d %d\\n\" % (\n",
        "            verts[i, 0], verts[i, 1], verts[i, 2],\n",
        "            norms[i, 0], norms[i, 1], norms[i, 2],\n",
        "            colors[i, 0], colors[i, 1], colors[i, 2],\n",
        "        ))\n",
        "\n",
        "    # Write face list\n",
        "    for i in range(faces.shape[0]):\n",
        "        ply_file.write(\"3 %d %d %d\\n\" % (faces[i, 0], faces[i, 1], faces[i, 2]))\n",
        "\n",
        "    ply_file.close()\n",
        "\n",
        "\n",
        "def pcwrite(filename, xyzrgb):\n",
        "    \"\"\"Save a point cloud to a polygon .ply file.\n",
        "  \"\"\"\n",
        "    xyz = xyzrgb[:, :3]\n",
        "    rgb = xyzrgb[:, 3:].astype(np.uint8)\n",
        "\n",
        "    # Write header\n",
        "    ply_file = open(filename, 'w')\n",
        "    ply_file.write(\"ply\\n\")\n",
        "    ply_file.write(\"format ascii 1.0\\n\")\n",
        "    ply_file.write(\"element vertex %d\\n\" % (xyz.shape[0]))\n",
        "    ply_file.write(\"property float x\\n\")\n",
        "    ply_file.write(\"property float y\\n\")\n",
        "    ply_file.write(\"property float z\\n\")\n",
        "    ply_file.write(\"property uchar red\\n\")\n",
        "    ply_file.write(\"property uchar green\\n\")\n",
        "    ply_file.write(\"property uchar blue\\n\")\n",
        "    ply_file.write(\"end_header\\n\")\n",
        "\n",
        "    # Write vertex list\n",
        "    for i in range(xyz.shape[0]):\n",
        "        ply_file.write(\"%f %f %f %d %d %d\\n\" % (\n",
        "            xyz[i, 0], xyz[i, 1], xyz[i, 2],\n",
        "            rgb[i, 0], rgb[i, 1], rgb[i, 2],\n",
        "        ))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUd6taHngTfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGES = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyCxgObUPfkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fuse(name):\n",
        "\n",
        "    print(\"Estimating voxel volume bounds...\")\n",
        "    images = IMAGES\n",
        "\n",
        "    camera_intrinsics_file = os.path.join(PATH, '../test', name, 'camera_calibration.csv')\n",
        "    camera_intrinsics = np.reshape(read_csv(file=camera_intrinsics_file, field='Camera Intrinsics'), (3, 3))\n",
        "\n",
        "    bounds = np.zeros((3, 2))\n",
        "\n",
        "    for i in range(0, images):\n",
        "\n",
        "        path = os.path.join(PATH, '../test', name, str(i+1) + '.exr')\n",
        "        depth = exr_to_depth(path, far_threshold=100)\n",
        "\n",
        "        camera_pose_file = os.path.join(PATH, '../test', name, 'frames.csv')\n",
        "        camera_pose = np.reshape(np.array(\n",
        "            read_csv(file=camera_pose_file, field='Matrix', row_number=i), dtype=float), (4, 4))\n",
        "\n",
        "        # Compute camera view frustum and extend convex hull\n",
        "        view_frust_pts = fusion.get_view_frustum(depth, camera_intrinsics, camera_pose)\n",
        "        bounds[:, 0] = np.minimum(bounds[:, 0], np.amin(view_frust_pts, axis=1))\n",
        "        bounds[:, 1] = np.maximum(bounds[:, 1], np.amax(view_frust_pts, axis=1))\n",
        "\n",
        "    print(\"Initializing voxel volume...\")\n",
        "    tsdf_vol = fusion.TSDFVolume(bounds, voxel_size=0.03)\n",
        "\n",
        "    # Loop through RGB-D images and fuse them together\n",
        "    t0_elapse = time.time()\n",
        "\n",
        "    for i in range(0, images):\n",
        "        print(\"Fusing frame %d/%d\" % (i + 1, images))\n",
        "\n",
        "        # Read RGB-D image and camera pose\n",
        "        path = os.path.join(PATH, '../test', name, str(i + 1) + '.exr')\n",
        "        color_image = exr_to_array(path)\n",
        "        depth = exr_to_depth(path)\n",
        "\n",
        "        camera_pose = np.reshape(np.array(\n",
        "            read_csv(file=camera_pose_file, field='Matrix', row_number=i), dtype=float), (4, 4))\n",
        "\n",
        "        # Integrate observation into voxel volume (assume color aligned with depth)\n",
        "        tsdf_vol.integrate(color_image, depth, camera_intrinsics, camera_pose, obs_weight=1.)\n",
        "\n",
        "    fps = images / (time.time() - t0_elapse)\n",
        "    print(\"Average FPS: {:.2f}\".format(fps))\n",
        "\n",
        "    # Get mesh from voxel volume and save to disk (can be viewed with Meshlab)\n",
        "    print(\"Saving mesh to mesh.ply...\")\n",
        "    verts, faces, norms, colors = tsdf_vol.get_mesh()\n",
        "\n",
        "    saving_path = os.path.join(PATH, '../test', name, 'mesh.ply')\n",
        "    fusion.meshwrite(saving_path, verts, faces, norms, colors)\n",
        "\n",
        "    # Get point cloud from voxel volume and save to disk (can be viewed with Meshlab)\n",
        "    # print(\"Saving point cloud to pc.ply...\")\n",
        "    # point_cloud = tsdf_vol.get_point_cloud()\n",
        "    # fusion.pcwrite(\"pc.ply\", point_cloud)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrIm41yufeCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fuse()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}